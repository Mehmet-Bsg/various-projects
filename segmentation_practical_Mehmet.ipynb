{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehmet-Bsg/various-projects/blob/main/segmentation_practical_Mehmet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_YUqkutrdO-"
      },
      "source": [
        "# Segmentation\n",
        "\n",
        "In this notebook we will train and test a deep learning model to perform binray image segmentation. \n",
        "\n",
        "This notebook deals with Whole Slide Images (WSI). Whole slide imaging, also known as virtual microscopy, refers to scanning a complete microscope slide and creating a single high-resolution digital file. "
      ],
      "id": "y_YUqkutrdO-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38cc29a8",
        "outputId": "31237846-b415-4bb2-8d42-55e4ea228185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "import imageio\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "38cc29a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBXjAU-KL1_3",
        "outputId": "11fdc9d1-c1cc-4c3b-f722-d7ccf279ae04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Data\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/gdrive/MyDrive/Data'"
      ],
      "id": "LBXjAU-KL1_3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc28ac0c"
      },
      "source": [
        "# Fetching data\n",
        "\n",
        "First step is to implement functions to send data to the training and testing pipeline. To do so, we implement the class DataGeneratorTissue used to select patches of images by customising keras DataGenerator class.  \n",
        "\n",
        "The function *get_random_patch_coord* randomly selects the coordinates of an image's patch, or crop. A *patch_coord* points to the top left corner of the corresponding patch. Thus the coordinates [y, x] gives for a patch of size [h, w] the image's patch *image* [y:y+h, x:x+w].\n",
        "\n",
        "The function *choose_patch_coord* calls *get_random_patch_coord* and should return the coordinates of a patch with at most 70% of background labels (pixel value of 0 in label). If it cannot be achieved after 10 tryouts, the function should return the coordinates of the patch with the lowest background labels found.  "
      ],
      "id": "fc28ac0c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f786f4a"
      },
      "outputs": [],
      "source": [
        "class DataGeneratorTissue(keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, path, prefix, batch_size, \n",
        "                 patch_size, nb_channels_in=3, nb_channels_out=1,\n",
        "                 geometric_augmentations=[], augmentation_ratio=None):\n",
        "        \n",
        "        self.path = path\n",
        "        self.prefix = prefix\n",
        "        self.get_data_dict()\n",
        "        self.batch_size = batch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.nb_channels_in = nb_channels_in\n",
        "        self.nb_channels_out = nb_channels_out\n",
        "        self.geometric_augmentations = []\n",
        "        self.augmentation_ratio = augmentation_ratio\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, batch_idx):\n",
        "        batch_data_idxs = self.data_idxs[batch_idx*self.batch_size:(batch_idx+1)*self.batch_size]\n",
        "        x, y = self.fetch_data(batch_data_idxs)\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.data_idxs = np.arange(len(self.data))\n",
        "        np.random.shuffle(self.data_idxs)\n",
        "    \n",
        "    def get_data_dict(self):\n",
        "        self.data = {}\n",
        "        for data_idx, image_name in enumerate(os.listdir(os.path.join(*[self.path, self.prefix, \"jpg\"]))):\n",
        "            self.data[data_idx] = image_name\n",
        "    \n",
        "    def get_random_patch_coord(self, image_size):\n",
        "        '''\n",
        "        image_size: (height, width)\n",
        "        '''\n",
        "        \n",
        "        \n",
        "        inf_coord = [0,0]\n",
        "        sup_coord = [image_size[0]-self.patch_size[0], image_size[1]-self.patch_size[1]]\n",
        "        patch_coord = np.random.randint(inf_coord, sup_coord)\n",
        "\n",
        "        ####  \n",
        "        \n",
        "        return patch_coord \n",
        "    \n",
        "    def choose_patch_coord(self, image_shape, label, threshold=0.7):\n",
        "        '''\n",
        "        image_shape: (height, width)\n",
        "        label: shape (height, width, channels)\n",
        "        '''\n",
        "        best_patch_coord = None\n",
        "        lowest_bg_per = np.inf\n",
        "        \n",
        "\n",
        "        for _ in range(10):\n",
        "            patch_coord = self.get_random_patch_coord(image_shape)\n",
        "            label_patch = label[patch_coord[0] : patch_coord[0] + self.patch_size[0], patch_coord[1] : patch_coord[1] + self.patch_size[1],0]\n",
        "            nb_pixels_b = np.sum(np.where(label_patch[...,0] == 0,1,0))\n",
        "            b_per = nb_pixels_b / (label_patch.shape[0] * label_patch.shape[1])\n",
        "            \n",
        "            if b_per < threshold : \n",
        "              return patch_coord\n",
        "\n",
        "            if b_per < lowest_bg_per:\n",
        "              best_patch_coord = patch_coord\n",
        "              lowest_bg_per = b_per\n",
        "        \n",
        "            \n",
        "        return best_patch_coord\n",
        "         \n",
        "        \n",
        "    def fetch_data(self, batch_data_idxs):\n",
        "        x = np.empty([self.batch_size, *self.patch_size, self.nb_channels_in])\n",
        "        y = np.empty([self.batch_size, *self.patch_size, self.nb_channels_out])\n",
        "        \n",
        "        for idx, data_idx in enumerate(batch_data_idxs):\n",
        "            image_file_path = os.path.join(*[self.path, self.prefix, \"jpg\", self.data[data_idx]])\n",
        "            image = imageio.imread(image_file_path)\n",
        "            \n",
        "            label_file_path = os.path.join(*[self.path, self.prefix, \"lbl\", self.data[data_idx]])\n",
        "            label = imageio.imread(label_file_path)\n",
        "            \n",
        "            image = np.float32(image/255)\n",
        "            label = np.expand_dims(np.float32(label/255), axis=-1)\n",
        "            \n",
        "            patch_coord = self.choose_patch_coord(list(image.shape[:2]), label)\n",
        "            \n",
        "            image_patch = image[patch_coord[0]:patch_coord[0]+self.patch_size[0], \n",
        "                                patch_coord[1]:patch_coord[1]+self.patch_size[1],:]\n",
        "            label_patch = label[patch_coord[0]:patch_coord[0]+self.patch_size[0], \n",
        "                                patch_coord[1]:patch_coord[1]+self.patch_size[1],:]\n",
        "            \n",
        "            if len(self.geometric_augmentations) != 0:\n",
        "                if np.random.binomial(1, self.augmentation_ratio) == 1:\n",
        "                    augm_idx = random.randint(0,len(self.geometric_augmentations)-1)\n",
        "                    image_patch, label_patch = self.geometric_augmentations[augm_idx](image_patch, label_patch)\n",
        "                              \n",
        "            x[idx:idx+1,...] = image_patch\n",
        "            y[idx:idx+1,...] = label_patch\n",
        "            \n",
        "        return x, y"
      ],
      "id": "1f786f4a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "973e10af"
      },
      "source": [
        "# U-Net model builder\n",
        "\n",
        "The deep learning model we will use is a U-Net model.\n",
        "\n",
        "We implement the encoder and decoder parts of the U-Net model with skip connections in the *build_unet_model* function using only *conv_block*, *up_sampler* and *keras.layers.Concatenate()* functions."
      ],
      "id": "973e10af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbea0d76"
      },
      "outputs": [],
      "source": [
        "def conv_block(filters, strides, last_activation=None):\n",
        "    if last_activation == None:\n",
        "        conv_block = keras.Sequential([keras.layers.Conv2D(filters=filters, kernel_size=3, \n",
        "                                                           strides=1, padding=\"same\", \n",
        "                                                           kernel_initializer = \"he_normal\"),\n",
        "                                       keras.layers.BatchNormalization(),\n",
        "                                       keras.layers.LeakyReLU(), \n",
        "                                       keras.layers.Conv2D(filters=filters, kernel_size=3, \n",
        "                                                           strides=strides, padding=\"same\", \n",
        "                                                           kernel_initializer = \"he_normal\"), \n",
        "                                       keras.layers.BatchNormalization(), \n",
        "                                       keras.layers.LeakyReLU()])\n",
        "    else:\n",
        "        conv_block = keras.Sequential([keras.layers.Conv2D(filters=filters, kernel_size=3, \n",
        "                                                           strides=strides, padding=\"same\", \n",
        "                                                           kernel_initializer = \"he_normal\"),\n",
        "                                       keras.layers.BatchNormalization(),\n",
        "                                       keras.layers.Activation(last_activation)])\n",
        "    return conv_block\n",
        "\n",
        "def up_sampler(filters):\n",
        "    up_sampler = keras.Sequential([keras.layers.Conv2DTranspose(filters=filters, kernel_size=2, \n",
        "                                                                strides=2, padding=\"valid\", \n",
        "                                                                kernel_initializer = \"he_normal\"), \n",
        "                                   keras.layers.BatchNormalization(), \n",
        "                                   keras.layers.LeakyReLU()])\n",
        "    return up_sampler\n",
        "    \n",
        "def build_unet_model(nb_channels_in, nb_channels_out, \n",
        "                     unet_filters, last_activation, \n",
        "                     image_size=[None, None]):\n",
        "    inputs = keras.Input([*image_size, nb_channels_in])\n",
        "    \n",
        "    skip = []\n",
        "\n",
        "    \n",
        "    # Encoder part\n",
        "    import copy \n",
        "    inp = inputs \n",
        "\n",
        "    for j in range (len(unet_filters)):\n",
        "      inp = conv_block(filters = unet_filters[j], strides = 1, last_activation = last_activation)(inp)\n",
        "      if j != len(unet_filters) -1 :\n",
        "        skip.insert(0,(inp))\n",
        "        inp = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(inp)\n",
        "  \n",
        "    # Decoder part\n",
        "    for x,y in enumerate(range(len(unet_filters)-2, -1, -1)):\n",
        "      inp = up_sampler(filters = unet_filters[y])(inp)\n",
        "      inp = keras.layers.concatenate([skip[x],inp], axis = -1)\n",
        "      inp = conv_block(filters = unet_filters[y], strides = 1, last_activation = last_activation)(inp)\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    outputs = conv_block(nb_channels_out, 1, last_activation)(inp)\n",
        "\n",
        "    unet_model = keras.Model(inputs, outputs)\n",
        "    return unet_model"
      ],
      "id": "fbea0d76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dee0ea60"
      },
      "source": [
        "# Segmentation loss\n",
        "\n",
        "The loss used here is the Jaccard loss, also known as Intersection over Union. As we are working with binary images as outputs, we want to maximize the overlap area of ground truth and predicted masks.\n",
        "\n",
        "We implement the computation of the cardinal of the intersection and the union between *y_true* and *y_pred*, stored in the variables *intersection* and *union* for the jaccard index-based loss. The function *K.sum()* should be sufficient to do so."
      ],
      "id": "dee0ea60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10d6c8f7"
      },
      "outputs": [],
      "source": [
        "def jaccard_loss(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis = -1)\n",
        "    union = K.sum(K.abs(y_true) + K.abs(y_pred), axis = -1) - intersection\n",
        "\n",
        "\n",
        "    \n",
        "    return 1 - (intersection + smooth) / (union + smooth)"
      ],
      "id": "10d6c8f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b79b93cd"
      },
      "source": [
        "# Data augmentation\n"
      ],
      "id": "b79b93cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc15cdf5"
      },
      "outputs": [],
      "source": [
        "def flip_aug(image, label):\n",
        "    flipped_image = np.flip(image, axis=1)\n",
        "    flipped_label = np.flip(label, axis=1)\n",
        "    return flipped_image, flipped_label\n",
        "\n",
        "def rot_aug(image, label):\n",
        "    image_rotation = ndimage.rotate(image, angle=random.randint(low=-20, high=20))\n",
        "    label_rotation = ndimage.rotate(label, angle=random.randint(low=-20, high=20))\n",
        "    return image_rotation, label_rotation"
      ],
      "id": "bc15cdf5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ac71ebf"
      },
      "source": [
        "# Model's training"
      ],
      "id": "4ac71ebf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd27f3a7",
        "outputId": "07af2e12-ceff-446b-ac25-33d468cd109d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " sequential_33 (Sequential)     (None, 128, 128, 8)  256         ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 8)   0           ['sequential_33[0][0]']          \n",
            "                                                                                                  \n",
            " sequential_34 (Sequential)     (None, 64, 64, 16)   1232        ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 32, 32, 16)  0           ['sequential_34[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " sequential_35 (Sequential)     (None, 32, 32, 32)   4768        ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 16, 16, 32)  0           ['sequential_35[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " sequential_36 (Sequential)     (None, 16, 16, 64)   18752       ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " sequential_37 (Sequential)     (None, 32, 32, 32)   8352        ['sequential_36[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 32, 32, 64)   0           ['sequential_35[0][0]',          \n",
            "                                                                  'sequential_37[0][0]']          \n",
            "                                                                                                  \n",
            " sequential_38 (Sequential)     (None, 32, 32, 32)   18592       ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " sequential_39 (Sequential)     (None, 64, 64, 16)   2128        ['sequential_38[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 64, 64, 32)   0           ['sequential_34[0][0]',          \n",
            "                                                                  'sequential_39[0][0]']          \n",
            "                                                                                                  \n",
            " sequential_40 (Sequential)     (None, 64, 64, 16)   4688        ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " sequential_41 (Sequential)     (None, 128, 128, 8)  552         ['sequential_40[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 128, 128, 16  0           ['sequential_33[0][0]',          \n",
            "                                )                                 'sequential_41[0][0]']          \n",
            "                                                                                                  \n",
            " sequential_42 (Sequential)     (None, 128, 128, 8)  1192        ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " sequential_43 (Sequential)     (None, 128, 128, 1)  77          ['sequential_42[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 60,589\n",
            "Trainable params: 60,123\n",
            "Non-trainable params: 466\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "path = \"./tissue\"\n",
        "\n",
        "models_dir = \"models\"\n",
        "if os.path.exists(models_dir) == False:\n",
        "    os.mkdir(models_dir)\n",
        "\n",
        "model_id = 1\n",
        "\n",
        "dt = datetime.now()\n",
        "timestamp = str(dt.hour) + ':' + str(dt.minute) + ':' + str(dt.second) + '-' + str(dt.day) + ':' + str(dt.month) + ':' + str(dt.year)\n",
        "model_name = \"modelID=\" + str(model_id) +  \"_timestamp=\" + timestamp\n",
        "\n",
        "model_dir = os.path.join(models_dir, model_name)\n",
        "if os.path.exists(model_dir) == False:\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "nb_channels_in = 3\n",
        "nb_channels_out = 1\n",
        "last_activation = \"sigmoid\"\n",
        "unet_filters = [8, 16, 32, 64]\n",
        "patch_size = [128, 128]\n",
        "batch_size = 5\n",
        "lr = 0.0001\n",
        "nb_epochs = 20\n",
        "\n",
        "model_parameters = {\"nb_channels_in\": nb_channels_in,\n",
        "                    \"nb_channels_out\": nb_channels_out,\n",
        "                    \"last_activation\": last_activation,\n",
        "                    \"unet_filters\": unet_filters,\n",
        "                    \"patch_size\": patch_size,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"lr\": lr,\n",
        "                    \"nb_epochs\": nb_epochs}\n",
        "\n",
        "json.dump(model_parameters, open(os.path.join(model_dir, \"model_parameters.json\"), \"w\"))\n",
        "\n",
        "model = build_unet_model(3, 1, unet_filters, \"sigmoid\", image_size = patch_size)\n",
        "model.summary()\n",
        "\n",
        "train_datagen = DataGeneratorTissue(path, \"train\", batch_size, \n",
        "                                    patch_size, 3, 1,\n",
        "                                    geometric_augmentations=[flip_aug, rot_aug], augmentation_ratio=0.2)\n",
        "\n",
        "val_datagen = DataGeneratorTissue(path, \"val\", batch_size, \n",
        "                                  patch_size, 3, 1)\n",
        "\n",
        "opt = keras.optimizers.Adam(lr)\n",
        "model.compile(optimizer=opt, loss=jaccard_loss)\n",
        "\n",
        "model_log_file_path = os.path.join(model_dir, \"log.csv\")\n",
        "best_model_weights_file_path = os.path.join(model_dir, \"best_model_weights.h5\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.CSVLogger(model_log_file_path),\n",
        "    keras.callbacks.ModelCheckpoint(best_model_weights_file_path, \n",
        "                                    save_best_only=True, save_weights_only=True)]\n"
      ],
      "id": "dd27f3a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDcgRxyrGiBY",
        "outputId": "ec207506-49b6-4181-c62a-e522937f45e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 11s 441ms/step - loss: 0.3099 - val_loss: 0.3692\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 8s 417ms/step - loss: 0.3030 - val_loss: 0.3532\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 10s 513ms/step - loss: 0.2964 - val_loss: 0.3541\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 9s 433ms/step - loss: 0.2896 - val_loss: 0.3492\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 9s 430ms/step - loss: 0.2861 - val_loss: 0.3438\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 9s 434ms/step - loss: 0.2730 - val_loss: 0.3435\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 8s 419ms/step - loss: 0.2786 - val_loss: 0.3439\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 9s 434ms/step - loss: 0.2684 - val_loss: 0.3410\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 11s 566ms/step - loss: 0.2757 - val_loss: 0.3378\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 9s 429ms/step - loss: 0.2697 - val_loss: 0.3355\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 9s 433ms/step - loss: 0.2663 - val_loss: 0.3326\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 9s 436ms/step - loss: 0.2663 - val_loss: 0.3311\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 9s 435ms/step - loss: 0.2649 - val_loss: 0.3158\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 8s 420ms/step - loss: 0.2613 - val_loss: 0.3172\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 9s 439ms/step - loss: 0.2621 - val_loss: 0.3040\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 8s 419ms/step - loss: 0.2588 - val_loss: 0.2915\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 9s 434ms/step - loss: 0.2654 - val_loss: 0.2727\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 9s 427ms/step - loss: 0.2712 - val_loss: 0.2831\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 8s 406ms/step - loss: 0.2652 - val_loss: 0.2758\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 9s 427ms/step - loss: 0.2605 - val_loss: 0.2573\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb718013e50>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_datagen, \n",
        "          epochs=nb_epochs,\n",
        "          validation_data=val_datagen, \n",
        "          verbose=1,\n",
        "          callbacks=callbacks)"
      ],
      "id": "BDcgRxyrGiBY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e66fbfb"
      },
      "source": [
        "# Training and Validation loss"
      ],
      "id": "0e66fbfb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "42069cb3",
        "outputId": "0752b6bc-c8c5-4eb6-d303-b87f00078cb2"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-467489d1fe6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/modelID=1_timestamp=17:31:34-24:10:2022/log.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(model_log_file_path, sep=\",\")\n",
        "plt.plot(df[\"epoch\"], df[\"loss\"], \"r\", label=\"training loss\")\n",
        "plt.plot(df[\"epoch\"], df[\"val_loss\"], \"b\", label=\"validation loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()"
      ],
      "id": "42069cb3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEn33k9V6-GX"
      },
      "source": [
        "### Some remarks : \n",
        "\n",
        "It seems like the traning and validation loss are not really similar. What is curious is that the loss don't follow the same varations. i was expecting two decreasing functions. It's either an error in my code or a curious distribution in the data between the training and validation set."
      ],
      "id": "tEn33k9V6-GX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ca5c9b9"
      },
      "source": [
        "# Model's inference function\n",
        "\n",
        "*make_apply_unet_model* is the function to call to embeds a U-Net model into a function in charge of the whole pipeline to get from an 8-bit image an 8-bit binary segmentation mask.  \n",
        "We implement the *apply_unet_model* function.\n",
        "The pipeline include:  \n",
        "* a [0,1]-normalization  \n",
        "* a padding of the image (so that its dimension are 2^{unet_depth = len(unet_filters)-1} divisible)  \n",
        "* the application of the UNet model  \n",
        "* an unpadding of the UNet model's output (to retrieve the initial image dimensions)  \n",
        "* the conversion of the UNet model's output into a binary segmentation mask by taking the label with the highest probability for each pixel  \n",
        "\n"
      ],
      "id": "6ca5c9b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "914b9cb9"
      },
      "outputs": [],
      "source": [
        "def pad_image(image, unet_depth):\n",
        "    shape = image.shape[:2]  \n",
        "    if shape[0]%2**unet_depth != 0 or shape[1]%2**unet_depth != 0:\n",
        "        new_shape = [shape[0] + 2**unet_depth - shape[0]%2**unet_depth, \n",
        "                     shape[1] + 2**unet_depth - shape[1]%2**unet_depth]\n",
        "        new_image = np.empty([*new_shape, 3])\n",
        "        new_image[0:shape[0], 0:shape[1], :] = image[...]\n",
        "        \n",
        "        new_image[0:shape[0],shape[1]:new_shape[1],:] = image[:,shape[1]-(new_shape[1]-shape[1]):shape[1],:]\n",
        "        new_image[shape[0]:new_shape[0],0:shape[1],:] = image[shape[0]-(new_shape[0]-shape[0]):shape[0],:,:]\n",
        "        new_image[shape[0]:new_shape[0],shape[1]:new_shape[1],:] = image[shape[0]-(new_shape[0]-shape[0]):shape[0],shape[1]-(new_shape[1]-shape[1]):shape[1],:]\n",
        "        \n",
        "        return new_image\n",
        "    else:\n",
        "        return image\n",
        "    \n",
        "def unpad_image(image, old_shape):\n",
        "    im_shape = image.shape[:2]\n",
        "    if im_shape[0] == old_shape[0] and im_shape[1] == old_shape[1]:\n",
        "        return image\n",
        "    else:\n",
        "        new_image = image[0:old_shape[0], 0:old_shape[1], :]\n",
        "        return new_image\n",
        "    \n",
        "def apply_unet_model(unet_model, unet_depth, image):\n",
        "\n",
        "    image = np.array(image, dtype = float)/255 # normalization\n",
        "    image_shape = image.shape\n",
        "    second_image = pad_image(image, unet_depth) # padding the image into a new one named second image\n",
        "    second_image = np.expand_dims(second_image, axis = 0)\n",
        "\n",
        "    output = unet_model(second_image) # applying unet model\n",
        "    \n",
        "    output = np.where(output > 0.5, 1, 0)\n",
        "\n",
        "    ini_dim_image = unpad_image(output[0], image_shape) # unpadding the image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "    return segm\n",
        "\n",
        "def make_apply_unet_model(unet_model, unet_depth):\n",
        "    return lambda image: apply_unet_model(unet_model, unet_depth, image)"
      ],
      "id": "914b9cb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abaacc51"
      },
      "source": [
        "# Model's application on test dataset\n",
        "\n"
      ],
      "id": "abaacc51"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4oBeUGHn1Tn"
      },
      "outputs": [],
      "source": [
        "indexes_to_test = [8, 42]  # indexes in [0, 42]"
      ],
      "id": "w4oBeUGHn1Tn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "oHDwnmhFDE5m",
        "outputId": "3027c312-cccc-4da0-ec37-c37cdf52a46d"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-94cd774eb1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                           model_parameters[\"last_activation\"])\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mapply_model\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmake_apply_unet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unet_filters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'models/modelID=1_timestamp=20:28:27-23:10:2022/best_model_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "model2load_id = 1\n",
        "\n",
        "for dir in os.listdir(\"models\"):\n",
        "    if len(dir.split(\"modelID\")) > 1:\n",
        "        id = int(dir.split(\"_\")[0].split(\"=\")[1])\n",
        "        if id == model2load_id:\n",
        "            model_dir = os.path.join(\"models\", dir)\n",
        "            break\n",
        "\n",
        "with open(os.path.join(model_dir, \"model_parameters.json\"), \"r\") as model_parameters_file:\n",
        "    model_parameters = json.load(model_parameters_file)\n",
        "\n",
        "weights_path = os.path.join(model_dir, \"best_model_weights.h5\")\n",
        "\n",
        "model2 = build_unet_model(model_parameters[\"nb_channels_in\"], \n",
        "                          model_parameters[\"nb_channels_out\"], \n",
        "                          model_parameters[\"unet_filters\"], \n",
        "                          model_parameters[\"last_activation\"])\n",
        "\n",
        "model2.load_weights(weights_path)\n",
        "    \n",
        "apply_model =  make_apply_unet_model(model2, len(model_parameters[\"unet_filters\"])-1) \n",
        "\n",
        "test_images_dir = os.path.join(path, \"test\")\n",
        "test_images_filenames = os.listdir(os.path.join(test_images_dir, \"jpg\"))\n",
        "\n",
        "for test_image_idx in indexes_to_test:\n",
        "\n",
        "  image = imageio.imread(os.path.join(*[test_images_dir, \"jpg\", test_images_filenames[test_image_idx]]))\n",
        "  label = imageio.imread(os.path.join(*[test_images_dir, \"lbl\", test_images_filenames[test_image_idx]]))\n",
        "\n",
        "  segm = apply_model(image)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 3, figsize=(18, 18))\n",
        "\n",
        "  ax[0].imshow(image)\n",
        "  ax[0].set_title(\"Input\")\n",
        "  ax[1].imshow(segm, cmap=\"gray\")\n",
        "  ax[1].set_title(\"Prediction\")\n",
        "  ax[2].imshow(label, cmap=\"gray\")\n",
        "  ax[2].set_title(\"Target\")"
      ],
      "id": "oHDwnmhFDE5m"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}